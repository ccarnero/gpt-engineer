* correr little llm con el lm que quiero: litellm --model ollama/codellama
* correr el gpt-engeniier:
  * poetry shell
  * OPENAI_API_BASE=http://0.0.0.0:8000 gpte projects/helloworldoffline